{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7dd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af064c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d88458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1e79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_variables = [\"DER_mass_MMC\",\n",
    " \"DER_mass_transverse_met_lep\", \n",
    " \"DER_mass_vis\",\n",
    " \"DER_pt_h\", \n",
    " \"DER_deltaeta_jet_jet\", \n",
    " \"DER_mass_jet_jet\", \n",
    " \"DER_prodeta_jet_jet\", \n",
    " \"DER_deltar_tau_lep\", \n",
    " \"DER_pt_tot\",\n",
    " \"DER_sum_pt\", \n",
    " \"DER_pt_ratio_lep_tau\", \n",
    " \"DER_met_phi_centrality\", \n",
    " \"DER_lep_eta_centrality\", \n",
    " \"PRI_tau_pt\",\n",
    " \"PRI_tau_eta\", \n",
    " \"PRI_tau_phi\",\n",
    " \"PRI_lep_pt\", \n",
    " \"PRI_lep_eta\",\n",
    " \"PRI_lep_phi\", \n",
    " \"PRI_met\", \n",
    " \"PRI_met_phi\",\n",
    " \"PRI_met_sumet\", \n",
    " \"PRI_jet_num\", \n",
    " \"PRI_jet_leading_pt\", \n",
    " \"PRI_jet_leading_eta\", \n",
    " \"PRI_jet_leading_phi\",\n",
    " \"PRI_jet_subleading_pt\", \n",
    " \"PRI_jet_subleading_eta\",\n",
    " \"PRI_jet_subleading_phi\", \n",
    " \"PRI_jet_all_pt\"]\n",
    "\n",
    "jet_num_index = dataset_variables.index('PRI_jet_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241f2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'data/train.csv' \n",
    "y_train, tx_train, ids_train = load_csv_data(data_train_path)\n",
    "\n",
    "data_test_path = 'data/test.csv' \n",
    "_, tx_test, ids_test = load_csv_data(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3273a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    ''' fill your code in here...\n",
    "    '''\n",
    "    centered_data = x - np.nanmean(x, axis=0)\n",
    "    std_data = centered_data / np.nanstd(centered_data, axis=0)\n",
    "    \n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53d33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels_gt, labels_pred):\n",
    "    \"\"\" Computes accuracy.\n",
    "    \n",
    "    Args:\n",
    "        labels_gt (np.array): GT labels of shape (N, ).\n",
    "        labels_pred (np.array): Predicted labels of shape (N, ).\n",
    "        \n",
    "    Returns:\n",
    "        float: Accuracy, in range [0, 1].\n",
    "    \"\"\"\n",
    "    np.sum(np.abs(labels_gt - labels_pred)==0)\n",
    "    \n",
    "    return np.sum(labels_gt == labels_pred) / labels_gt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3efdc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jets = [0, 1, 2, 3]\n",
    "\n",
    "def prepare_into_jet_subsets(y, tx, ids):\n",
    "    tx[np.where(tx == -999)] = np.nan\n",
    "    std_tx = standardize(tx)\n",
    "    std_tx[:, jet_num_index] = tx[:, jet_num_index]\n",
    "    \n",
    "    y_split_temp = {}\n",
    "    tx_split_temp = {}\n",
    "    split_ids_temp = {}\n",
    "\n",
    "    #Splits the data into 4 subsets, one for each jet number.\n",
    "    for jet in jets:\n",
    "        jet_ids = np.where(std_tx[:, jet_num_index] == jet)\n",
    "        split_ids_temp[jet] = ids[jet_ids]\n",
    "        if(y.shape != ()):\n",
    "            y_split_temp[jet] = y[jet_ids]\n",
    "        tx_split_temp[jet] = std_tx[jet_ids]\n",
    "    return y_split_temp, tx_split_temp, split_ids_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8f1e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split, tx_split, ids_split = prepare_into_jet_subsets(y_train, tx_train, ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6aa3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data features where every entry is nan\n",
    "del_indices = {}\n",
    "for jet in jets:\n",
    "    id_nans = np.where(np.isnan(tx_split[jet]))\n",
    "    \n",
    "    nan_index, nan_counts = np.unique(id_nans[1], return_counts=True)\n",
    "    indices_todel = nan_index[nan_counts == len(tx_split[jet][:,0])]\n",
    "    \n",
    "    del_indices[jet] = indices_todel\n",
    "    \n",
    "    tx_split[jet] = np.delete(tx_split[jet], indices_todel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddacc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nans_to_mean(tx_split_ntm, jet):\n",
    "    #Initialize variables\n",
    "    tx_jet = tx_split_ntm[jet]\n",
    "    means_without_outliers = np.zeros(tx_jet.shape[1])\n",
    "    counts_without_outliers = np.zeros(tx_jet.shape[1])\n",
    "    \n",
    "    #Counts the number of valid entries and sums their value\n",
    "    for entry in tx_jet:\n",
    "        for id_point, point in enumerate(entry):\n",
    "            if(not np.isnan(point)):\n",
    "                means_without_outliers[id_point] += point\n",
    "                counts_without_outliers[id_point] += 1\n",
    "            \n",
    "    #Computes the mean of valid entries\n",
    "    means_without_outliers /= counts_without_outliers\n",
    "    \n",
    "    tx_jet_no_nan = tx_jet.copy()\n",
    "    bad_variables = np.where(np.isnan(tx_jet))\n",
    "\n",
    "    #Replaces every nan variable by the mean of that variable\n",
    "    for entry, point in zip(bad_variables[0], bad_variables[1]):\n",
    "        tx_jet_no_nan[entry, point] = means_without_outliers[point]\n",
    "    return tx_jet_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbca59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns every remaining nan into the mean of the variable in that jet subset.\n",
    "for jet in jets:\n",
    "        tx_split[jet] = nans_to_mean(tx_split, jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa27f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge done for jet subset nr 0\n",
      "Ridge done for jet subset nr 1\n",
      "Ridge done for jet subset nr 2\n",
      "Ridge done for jet subset nr 3\n"
     ]
    }
   ],
   "source": [
    "#Runs ridge regression \n",
    "best_degrees = {}\n",
    "w_preds = {}\n",
    "for jet in jets:\n",
    "    degrees = np.arange(2,4)\n",
    "    k_fold = 3\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    #Computes the best degree and lambda\n",
    "    best_degree, best_lambda, _ = best_degree_selection(tx_split[jet], y_split[jet],\n",
    "                                                        degrees, k_fold, lambdas, seed = 1)\n",
    "    #Saves the degree for predictions\n",
    "    best_degrees[jet] = best_degree\n",
    "    \n",
    "    poly_tr = build_poly(tx_split[jet], best_degree)\n",
    "    w_pred, _ = ridge_regression(y_split[jet], poly_tr, best_lambda)\n",
    "\n",
    "    w_preds[jet] = w_pred\n",
    "    print(\"Ridge done for jet subset nr\", jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40aa1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the data for testing in the same way as for the training data\n",
    "_, te_tx_split, te_ids_split = prepare_into_jet_subsets(np.array(0), tx_test, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5ca09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes the same data features as for the train data\n",
    "for jet in jets:\n",
    "    te_tx_split[jet] = np.delete(te_tx_split[jet], del_indices[jet], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "051408ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the remaing nans to the mean of the variable\n",
    "for jet in jets:\n",
    "    te_tx_split[jet] = nans_to_mean(te_tx_split, jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a71671b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the labels\n",
    "predicted_labels = {}\n",
    "for jet in jets:\n",
    "    poly_te = build_poly(te_tx_split[jet], best_degrees[jet])\n",
    "    predicted_labels[jet] = predict_labels(w_preds[jet], poly_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "639c2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_final = np.concatenate((predicted_labels[0], predicted_labels[1], predicted_labels[2], predicted_labels[3]))\n",
    "ids_final = np.concatenate((te_ids_split[0], te_ids_split[1], te_ids_split[2], te_ids_split[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87b99049",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_final, pred_labels_final, \"prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
